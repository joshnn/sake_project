{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List, Union, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward\n",
    "from transformers.activations import ACT2FN\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics as tm\n",
    "# import bitsandbytes as bnb\n",
    "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
    "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
    "NODE_OP_CODES = 120\n",
    "NODE_FEATS = 140\n",
    "CONFIG_FEATS = 24\n",
    "NODE_CONFIG_FEATS = 18\n",
    "DATA_DIR = \"../input/predict-ai-model-runtime/npz_all/npz\"\n",
    "\n",
    "\n",
    "def generate_tile_df() -> pd.DataFrame:\n",
    "    tile_df = pd.DataFrame({'paths': [elem for elem in (Path(DATA_DIR) / 'tile').rglob(\"*\") if elem.is_file()]}).assign(\n",
    "        split=lambda df: df.paths.apply(lambda x: x.parent.name),\n",
    "        configuration=lambda df: df.paths.apply(lambda x: x.parent.parent.name),\n",
    "        extra=lambda df: df.paths.apply(lambda x: x.parent.parent.parent.name),\n",
    "        model_name=lambda df: df.paths.apply(lambda x: x.stem),\n",
    "        collection=lambda df: df.extra + ':' + df.configuration ,\n",
    "        ID=lambda df: df.collection + ':' + df.model_name ,\n",
    "        paths = lambda df: df.paths.apply(lambda x: str(x))\n",
    "    )\n",
    "    return tile_df\n",
    "tile_df = generate_tile_df()\n",
    "tile_df.head()\n",
    "\"\"\"\n",
    "paths\tsplit\tconfiguration\textra\tmodel_name\tcollection\tID\n",
    "0\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tresnet_v1_50_official_batch_128_bf16_2bea628b7...\ttile:xla\ttile:xla:resnet_v1_50_official_batch_128_bf16_...\n",
    "1\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_40fa8f86f121f00a\ttile:xla\ttile:xla:inception_v3_batch_128_train_40fa8f86...\n",
    "2\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_-23e94c034a65a177\ttile:xla\ttile:xla:inception_v3_batch_128_train_-23e94c0...\n",
    "3\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_171f4371caf28639\ttile:xla\ttile:xla:inception_v3_batch_128_train_171f4371...\n",
    "4\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tmlperf_bert_batch_24_2x2_-25e30862c042a2b8\ttile:xla\ttile:xla:mlperf_bert_batch_24_2x2_-25e30862c04...\n",
    "\"\"\"\n",
    "#Dataset\n",
    "#Create an Adjacency matrix for masking the attention\n",
    "#Creates a virtual first node equivalent to the [CLS] token which contains the global config for tile cases, while layout node configuration goes to the corresponding node position\n",
    "def edges_adjacency(edges: torch.Tensor, add_diagonal=True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate an adjacency matrix from the edges\n",
    "    Args:\n",
    "        edges: Tensor of shape (num_edges, 2) with the edges\n",
    "        add_diagonal: Boolean indicating if the diagonal should be added to the adjacency matrix\n",
    "    Returns:\n",
    "        adjacency_matrix: Tensor of shape (num_nodes, num_nodes) with the adjacency matrix\n",
    "    \"\"\"\n",
    "    adjacency_matrix = torch.zeros((edges.max() + 1, edges.max() + 1))\n",
    "    adjacency_matrix[edges[:, 0], edges[:, 1]] = 1\n",
    "    if add_diagonal:\n",
    "        diag_idx = torch.arange(adjacency_matrix.shape[0])\n",
    "        adjacency_matrix[diag_idx, diag_idx] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "def tile_loader(path):\n",
    "    tile_dict =  dict(np.load(path))\n",
    "    tile_dict = {k: torch.from_numpy(v) for k, v in tile_dict.items()}\n",
    "    tile_dict['edges_adjecency'] = edges_adjacency(tile_dict['edge_index'])\n",
    "    return tile_dict\n",
    "\n",
    "def node_cls_token(elem_dict, shift_node_config_ids:bool=True):\n",
    "    \"\"\"\n",
    "    Add a cls token to the node opcode, features, edges adjacency matrix, shift node_config_ids by 1 to account for the cls token\n",
    "    Args:\n",
    "        elem_dict: Dictionary with the elements of the tile\n",
    "    Returns:\n",
    "        elem_dict: Dictionary with the elements of the tile with the cls token\n",
    "    \"\"\"\n",
    "    elem_dict['node_opcode'] = torch.cat([torch.tensor([0]), elem_dict['node_opcode']]) # Introduce [CLS] node\n",
    "    elem_dict['node_feat'] = torch.cat([torch.zeros((1, elem_dict['node_feat'].shape[1])), elem_dict['node_feat']])\n",
    "    elem_dict['edges_adjecency'] = F.pad(elem_dict['edges_adjecency'], (1,0,1,0), value=1)\n",
    "    if 'node_config_ids' in elem_dict and shift_node_config_ids:\n",
    "        elem_dict['node_config_ids'] = elem_dict['node_config_ids'] + 1 # Shift Node Config IDs to take in to account [CLS] node\n",
    "    return elem_dict\n",
    "\n",
    "\n",
    "class TileDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame ,add_cls_token:bool=True, num_configs:int=10,  max_configs:Optional[int]=None):\n",
    "        self.df = df\n",
    "        self.add_cls_token = add_cls_token\n",
    "        self.num_configs = num_configs\n",
    "        self.max_configs = max_configs  \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def select_configs(self, total_configs:int):\n",
    "        if self.max_configs is not None:\n",
    "            total_configs = min(total_configs, self.max_configs)\n",
    "        if self.num_configs == -1:\n",
    "            return np.arange(total_configs)\n",
    "        if total_configs < self.num_configs:\n",
    "            return np.random.choice(total_configs, self.num_configs, replace=True)\n",
    "        return  np.random.choice(total_configs, self.num_configs, replace=False)\n",
    "    \n",
    "    def __getitem__(self, idx:int, selected_configs:List[int]=None):\n",
    "        tile_dict = tile_loader(self.df.paths[idx])\n",
    "        if selected_configs is None:\n",
    "            selected_configs = self.select_configs(tile_dict['config_feat'].shape[0])\n",
    "        tile_dict['node_config_feat'] = tile_dict.pop('config_feat')[selected_configs]\n",
    "        tile_dict['node_config_feat'] = F.pad(tile_dict['node_config_feat'].unsqueeze(1), (0,NODE_CONFIG_FEATS))\n",
    "        tile_dict['config_runtime'] = tile_dict['config_runtime'][selected_configs].float()\n",
    "        tile_dict['config_runtime'] /= tile_dict['config_runtime_normalizers'][selected_configs].float()\n",
    "        tile_dict['node_config_ids'] = torch.zeros((1,))\n",
    "        tile_dict['selected_idxs'] = selected_configs\n",
    "        if self.add_cls_token:\n",
    "            tile_dict = node_cls_token(tile_dict, False)\n",
    "        return tile_dict\n",
    "\"\"\"\n",
    "edges_adjacencyé–¢æ•°: å…¥åŠ›: ã‚¨ãƒƒã‚¸ã®ãƒ†ãƒ³ã‚½ãƒ«ã¨å¯¾è§’ç·šã‚’è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹ã®ãƒ–ãƒ¼ãƒ«å€¤ãƒ•ãƒ©ã‚°ã€‚ å‡¦ç†: ã‚¨ãƒƒã‚¸ã®ãƒ†ãƒ³ã‚½ãƒ«ã‹ã‚‰éš£æŽ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å¯¾è§’ç·šã‚’è¿½åŠ ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚ã‚ã‚Šã¾ã™ã€‚ å‡ºåŠ›: éš£æŽ¥è¡Œåˆ—ã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚\n",
    "tile_loaderé–¢æ•°: å…¥åŠ›: ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´æ‰€ï¼‰ã€‚ å‡¦ç†: NumPyãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ãã®å†…å®¹ã‚’PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚¨ãƒƒã‚¸ã®éš£æŽ¥è¡Œåˆ—ã‚‚ç”Ÿæˆã—ã¾ã™ã€‚ å‡ºåŠ›: ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®è¾žæ›¸ï¼ˆãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã•ã‚Œã€éš£æŽ¥è¡Œåˆ—ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ï¼‰ã€‚\n",
    "node_cls_tokené–¢æ•°: å…¥åŠ›: ã‚¿ã‚¤ãƒ«ã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®è¾žæ›¸ã€‚ å‡¦ç†: [CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒŽãƒ¼ãƒ‰ã®ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã€ç‰¹å¾´ã€ã‚¨ãƒƒã‚¸ã®éš£æŽ¥è¡Œåˆ—ã«è¿½åŠ ã—ã¾ã™ã€‚ã¾ãŸã€ãƒŽãƒ¼ãƒ‰ã®è¨­å®šIDã‚‚1ã ã‘ã‚·ãƒ•ãƒˆã—ã¾ã™ã€‚ å‡ºåŠ›: [CLS]ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¿½åŠ ã•ã‚ŒãŸã‚¿ã‚¤ãƒ«ã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®è¾žæ›¸ã€‚\n",
    "TileDatasetã‚¯ãƒ©ã‚¹: å½¹å‰²: ã‚¿ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç®¡ç†ã—ã€ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚ initãƒ¡ã‚½ãƒƒãƒ‰: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã®è¿½åŠ ã€è¨­å®šã®æ•°ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚ lenãƒ¡ã‚½ãƒƒãƒ‰: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é•·ã•ï¼ˆã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ç·æ•°ï¼‰ã‚’è¿”ã—ã¾ã™ã€‚ select_configsãƒ¡ã‚½ãƒƒãƒ‰: ç·è¨­å®šã‹ã‚‰ç‰¹å®šã®è¨­å®šã‚’é¸æŠžã—ã¾ã™ã€‚ getitemãƒ¡ã‚½ãƒƒãƒ‰: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã€å¿…è¦ã«å¿œã˜ã¦å‰å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ å‡¦ç†ã®æµã‚Œ: ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒƒã‚¸ã‹ã‚‰éš£æŽ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ NumPyãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚ [CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã¦ã€ãƒŽãƒ¼ãƒ‰ã‚„ã‚¨ãƒƒã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£ãƒ»æ›´æ–°ã—ã¾ã™ã€‚ TileDatasetã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†ã‚’åŠ¹çŽ‡çš„ã«è¡Œã„ã¾ã™ã€‚ ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã‚°ãƒ©ãƒ•ã®ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹çŽ‡çš„ã«å‡¦ç†ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„è©•ä¾¡ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚\n",
    "\"\"\"\n",
    "\n",
    "tile_dataset = TileDataset(tile_df)\n",
    "elem = tile_dataset[0]\n",
    "for k,v in elem.items():\n",
    "    print(k, v.shape)\n",
    "node_feat torch.Size([81, 140])\n",
    "node_opcode torch.Size([81])\n",
    "edge_index torch.Size([86, 2])\n",
    "config_runtime torch.Size([10])\n",
    "config_runtime_normalizers torch.Size([3246])\n",
    "edges_adjecency torch.Size([81, 81])\n",
    "node_config_feat torch.Size([10, 1, 42])\n",
    "node_config_ids torch.Size([1])\n",
    "selected_idxs (10,)\n",
    "elem['edges_adjecency']\n",
    "\"\"\"\n",
    "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
    "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
    "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
    "        ...,\n",
    "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
    "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
    "        [1., 0., 0.,  ..., 1., 1., 1.]])\n",
    "\"\"\"\n",
    "#Collator\n",
    "def pad_edge_adjacency(edges_adjacency_list):\n",
    "    max_len = max([elem.shape[0] for elem in edges_adjacency_list])\n",
    "    return torch.stack([F.pad(elem, (0, max_len-elem.shape[0], 0, max_len-elem.shape[0]), value=0) for elem in edges_adjacency_list], dim=0)\n",
    "\n",
    "@dataclass\n",
    "class LayoutCollator:\n",
    "    pad_to_multiple_of: int = 64\n",
    "    targets:bool = True\n",
    "    padding_idx:int = 120\n",
    "    node_padding_idx:int = 0\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        output = {}\n",
    "        max_node_len = max([elem['node_opcode'].shape[0] for elem in batch])\n",
    "        node_pad_amount = self.pad_to_multiple_of - max_node_len % max(self.pad_to_multiple_of, 1)\n",
    "        output['node_opcode'] = F.pad(pad_sequence([elem['node_opcode'] for elem in batch], batch_first=True, padding_value=self.padding_idx),\n",
    "                                      (0, node_pad_amount), value=self.padding_idx).long()\n",
    "        output['node_feat'] = F.pad(pad_sequence([elem['node_feat'] for elem in batch], batch_first=True),\n",
    "                                    (0,0,0, node_pad_amount), value=0)\n",
    "        output['edges_adjecency'] = F.pad(pad_edge_adjacency([elem['edges_adjecency'] for elem in batch]),\n",
    "                                          (0, node_pad_amount, 0, node_pad_amount), value=0)\n",
    "        output['node_attn_mask'] = F.pad(pad_sequence([torch.ones(len(elem['node_opcode'])) for elem in batch], batch_first=True),\n",
    "                                         (0, node_pad_amount), value=0)\n",
    "\n",
    "        max_node_config_len = max([elem['node_config_ids'].shape[0] for elem in batch])\n",
    "        node_config_pad_amount = self.pad_to_multiple_of - max_node_config_len % max(self.pad_to_multiple_of, 1)\n",
    "        output['node_config_ids'] = F.pad(pad_sequence([elem['node_config_ids'] for elem in batch], batch_first=True),\n",
    "                                         (0, node_config_pad_amount), value=0).long()\n",
    "        padded_node_config_feat = pad_sequence([elem['node_config_feat'].permute(1,0,2) for elem in batch], batch_first=True, padding_value=-1)\n",
    "        padded_node_config_feat = F.pad(padded_node_config_feat.permute(0,2,1,3),\n",
    "                                           (0,0,0, node_config_pad_amount,0,0), value=-1)\n",
    "        \n",
    "        output['node_config_feat'] = torch.where(padded_node_config_feat!=-1, padded_node_config_feat, self.node_padding_idx)\n",
    "                                      \n",
    "        output['config_idxs'] = torch.stack([torch.from_numpy(elem['selected_idxs']) for elem in batch])\n",
    "        \n",
    "        if self.targets:\n",
    "            output['config_runtime'] = pad_sequence([elem['config_runtime'].float() for elem in batch], batch_first=True)\n",
    "        return output\n",
    "\"\"\"\n",
    "ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒƒãƒå‡¦ç†ã‚’åŠ¹çŽ‡çš„ã«è¡Œã†ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã¨ãã®è£œåŠ©é–¢æ•°ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ãƒ¼ã‚¿ã¯ã€ãƒãƒƒãƒå†…ã®ãƒ‡ãƒ¼ã‚¿è¦ç´ ã‚’é©åˆ‡ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã€ãƒãƒƒãƒå‡¦ç†ã‚’åŠ¹çŽ‡åŒ–ã™ã‚‹å½¹å‰²ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "pad_edge_adjacencyé–¢æ•°: å…¥åŠ›: ã‚¨ãƒƒã‚¸ã®éš£æŽ¥è¡Œåˆ—ã®ãƒªã‚¹ãƒˆã€‚ å‡¦ç†: ãƒªã‚¹ãƒˆå†…ã®ã™ã¹ã¦ã®éš£æŽ¥è¡Œåˆ—ã‚’ã€æœ€å¤§ã®è¡Œåˆ—ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚ å‡ºåŠ›: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸéš£æŽ¥è¡Œåˆ—ã®ãƒãƒƒãƒã€‚\n",
    "LayoutCollatorã‚¯ãƒ©ã‚¹: å½¹å‰²: ãƒãƒƒãƒå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã€ä¸€è²«ã—ãŸå½¢çŠ¶ã®ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒƒãƒå‡¦ç†ãŒåŠ¹çŽ‡çš„ã«è¡Œãˆã¾ã™ã€‚ pad_to_multiple_ofå±žæ€§: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é•·ã•ãŒã“ã®å€¤ã®å€æ•°ã«ãªã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚ targetså±žæ€§: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆä¾‹: ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ï¼‰ã‚‚å‡ºåŠ›ã«å«ã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚ padding_idxå±žæ€§: ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã«ä½¿ç”¨ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å€¤ã€‚ node_padding_idxå±žæ€§: ãƒŽãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã«ä½¿ç”¨ã™ã‚‹å€¤ã€‚ callãƒ¡ã‚½ãƒƒãƒ‰: ãƒãƒƒãƒã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚ å…¥åŠ›: ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã€‚ å‡¦ç†: å„ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ãƒŽãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã€ç‰¹å¾´é‡ãªã©ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã€ä¸€è²«ã—ãŸå½¢çŠ¶ã«ã—ã¾ã™ã€‚ å‡ºåŠ›: ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚Œã€æ•´å½¢ã•ã‚ŒãŸãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã€‚ å…·ä½“çš„ãªå‡¦ç†å†…å®¹: ãƒŽãƒ¼ãƒ‰ã®ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: ãƒãƒƒãƒå†…ã®ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã§ãƒŽãƒ¼ãƒ‰ã®ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã‚’æœ€å¤§ã®é•·ã•ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚ ãƒŽãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: ãƒãƒƒãƒå†…ã®ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã§ãƒŽãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ã‚’æœ€å¤§ã®é•·ã•ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚ ã‚¨ãƒƒã‚¸ã®éš£æŽ¥è¡Œåˆ—ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: pad_edge_adjacencyé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¨ãƒƒã‚¸ã®éš£æŽ¥è¡Œåˆ—ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚ ãƒŽãƒ¼ãƒ‰ã®è¨­å®šIDã¨ç‰¹å¾´é‡ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: ãƒãƒƒãƒå†…ã®ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã§ãƒŽãƒ¼ãƒ‰ã®è¨­å®šIDã¨ç‰¹å¾´é‡ã‚’æœ€å¤§ã®é•·ã•ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ï¼ˆtargetså±žæ€§ãŒTrueã®å ´åˆï¼‰ã€‚ ã“ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã¯ã€ãƒãƒƒãƒå‡¦ç†ä¸­ã«ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚’ä¸€è²«ã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„è©•ä¾¡ã‚’åŠ¹çŽ‡çš„ã«è¡Œã†ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\"\"\"\n",
    "\n",
    "collate_fn = LayoutCollator(64)\n",
    "batch = collate_fn([tile_dataset[0], tile_dataset[1]])\n",
    "for k,v in batch.items():\n",
    "    print(k,v.shape)\n",
    "node_opcode torch.Size([2, 128])\n",
    "node_feat torch.Size([2, 128, 140])\n",
    "edges_adjecency torch.Size([2, 128, 128])\n",
    "node_attn_mask torch.Size([2, 128])\n",
    "node_config_ids torch.Size([2, 64])\n",
    "node_config_feat torch.Size([2, 10, 64, 42])\n",
    "config_idxs torch.Size([2, 10])\n",
    "config_runtime torch.Size([2, 10])\n",
    "Model - Config\n",
    "@dataclass\n",
    "class GraphConfig:\n",
    "    num_hidden_layers: int = 8\n",
    "    hidden_size: int = 256\n",
    "    num_attention_heads: int = 16\n",
    "    intermediate_size: int = 64\n",
    "    chunk_size_feed_forward: int = 64\n",
    "    attention_probs_dropout_prob: float = 0.0\n",
    "    max_position_embeddings: int = 512\n",
    "    hidden_dropout_prob: float = 0.0\n",
    "    layer_norm_eps: float = 1e-12\n",
    "    hidden_act: str = 'gelu'\n",
    "    initializer_range: float = 0.02\n",
    "    output_hidden_states: bool = False\n",
    "    output_attentions: bool = False\n",
    "    gradient_checkpointing: bool = False\n",
    "    margin: float = 0.1\n",
    "    number_permutations: int = 10\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.embedding_size = self.hidden_size\n",
    "    \n",
    "    def validate(self):\n",
    "        if self.hidden_size % self.num_attention_heads != 0 and not hasattr(self, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({self.num_attention_heads})\"\n",
    "            )\n",
    "            \n",
    "    def save_config(self, path):\n",
    "        config = asdict(self)\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(config, f)\n",
    "            \n",
    "    @classmethod\n",
    "    def load_config(cls, path):\n",
    "        with open(path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        return cls(**config)\n",
    "\n",
    "\"\"\"\n",
    "ã‚°ãƒ©ãƒ•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¾ãŸã¯ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒžãƒ¼ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’ç®¡ç†ã™ã‚‹GraphConfigã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨­å®šã‚’æ ¼ç´ã€æ¤œè¨¼ã€ä¿å­˜ã€ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚\n",
    "\n",
    "GraphConfig ã‚¯ãƒ©ã‚¹ã®å±žæ€§ï¼š num_hidden_layers: ãƒ¢ãƒ‡ãƒ«ã®éš ã‚Œå±¤ã®æ•°ã€‚ hidden_size: éš ã‚Œå±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ï¼ˆæ¬¡å…ƒæ•°ï¼‰ã€‚ num_attention_heads: ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã®æ•°ã€‚ intermediate_size: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ¡ãƒ‡ã‚£ã‚¨ã‚¤ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éƒ¨åˆ†ï¼‰ã®ã‚µã‚¤ã‚ºã€‚ chunk_size_feed_forward: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã€‚ attention_probs_dropout_prob: ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ç¢ºçŽ‡ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆçŽ‡ã€‚ max_position_embeddings: æœ€å¤§ä½ç½®åŸ‹ã‚è¾¼ã¿ã®ã‚µã‚¤ã‚ºã€‚ hidden_dropout_prob: éš ã‚Œå±¤ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆçŽ‡ã€‚ layer_norm_eps: ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ã®epsilonï¼ˆå®‰å®šæ€§ã®ãŸã‚ã®å°ã•ã„å€¤ï¼‰ã€‚ hidden_act: éš ã‚Œå±¤ã®æ´»æ€§åŒ–é–¢æ•°ã€‚ initializer_range: é‡ã¿ã®åˆæœŸåŒ–ã®ç¯„å›²ã€‚ output_hidden_states: éš ã‚ŒçŠ¶æ…‹ã‚’å‡ºåŠ›ã™ã‚‹ã‹ã©ã†ã‹ã€‚ output_attentions: ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’å‡ºåŠ›ã™ã‚‹ã‹ã©ã†ã‹ã€‚ gradient_checkpointing: å‹¾é…ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹çŽ‡ã®ãŸã‚ï¼‰ã€‚ margin: ãƒ­ã‚¹è¨ˆç®—ã§ä½¿ç”¨ã™ã‚‹ãƒžãƒ¼ã‚¸ãƒ³ã€‚ number_permutations: ãƒ‘ãƒ¼ãƒŸãƒ¥ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ•°ã€‚\n",
    "\n",
    "GraphConfig ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ï¼š post_init ãƒ¡ã‚½ãƒƒãƒ‰: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ãŸå¾Œã«ã€embedding_size ã‚’ hidden_size ã¨åŒã˜å€¤ã§è¨­å®šã—ã¾ã™ã€‚ validate ãƒ¡ã‚½ãƒƒãƒ‰: ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚ç‰¹ã«ã€hidden_size ãŒ num_attention_heads ã®å€æ•°ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚ save_config ãƒ¡ã‚½ãƒƒãƒ‰: ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚ å…¥åŠ›: è¨­å®šã‚’ä¿å­˜ã™ã‚‹ãƒ‘ã‚¹ã€‚ å‡¦ç†: è¨­å®šãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã‚’JSONã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã™ã€‚ load_config ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰: JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ å…¥åŠ›: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚ å‡ºåŠ›: ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè¨­å®šã‚’æŒã¤æ–°ã—ã„ GraphConfig ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚\n",
    "\n",
    "Loss\n",
    "Uses Ranking loss to compare different configuration\n",
    "Compares does configurations with different indexes, masks those cases where the permutation returns the same element\n",
    "Compares multiple configurations in each run\n",
    "\"\"\"\n",
    "class MultiElementRankLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function that compares the output of the model with the output of the model with a permutation of the elements\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin:float=0.0, number_permutations:int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.MarginRankingLoss(margin=margin, reduction = 'none')\n",
    "        self.number_permutations = number_permutations\n",
    "    \n",
    "    def calculate_rank_loss(self,\n",
    "                            outputs: torch.Tensor,\n",
    "                            config_runtime: torch.Tensor,\n",
    "                            config_idxs: torch.Tensor\n",
    "                            ):\n",
    "        \"\"\"\n",
    "        Generates a permutation of the predictions and targets and calculates the loss MarginRankingLoss against the permutation\n",
    "        Args:\n",
    "            outputs: Tensor of shape (bs, seq_len) with the outputs of the model\n",
    "            config_runtime: Tensor of shape (bs, seq_len) with the runtime of the model\n",
    "            config_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "            and 0 in the positions of the padding\n",
    "        Returns:\n",
    "            loss: Tensor of shape (bs, seq_len) with the loss for each element in the batch\n",
    "        \"\"\"\n",
    "        bs, num_configs = outputs.shape\n",
    "        permutation = torch.randperm(num_configs) \n",
    "        permuted_idxs = config_idxs[:, permutation]\n",
    "        # We mask those cases where we compare the same configuration\n",
    "        config_mask = torch.where(config_idxs != permuted_idxs, 1, 0)\n",
    "        permuted_runtime = config_runtime[:, permutation]\n",
    "        labels = 2*((config_runtime - permuted_runtime) > 0) -1\n",
    "        permuted_output = outputs[:, permutation]\n",
    "        loss = self.loss_fn(outputs.view(-1,1), permuted_output.view(-1,1), labels.view(-1,1))\n",
    "        loss = loss.view(bs, num_configs) * config_mask\n",
    "        return loss.mean()\n",
    "                \n",
    "    \n",
    "    def forward(self,\n",
    "                outputs: torch.Tensor,\n",
    "                config_runtime: torch.Tensor,\n",
    "                config_idxs: torch.Tensor\n",
    "                ):\n",
    "        loss = 0 \n",
    "        for _ in range(self.number_permutations):\n",
    "            loss += self.calculate_rank_loss(outputs, config_runtime, config_idxs)\n",
    "        return loss/ self.number_permutations\n",
    "\"\"\"\n",
    "ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€è¤‡æ•°ã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°æå¤±ï¼ˆMultiElementRankLossï¼‰ã‚’è¨ˆç®—ã™ã‚‹PyTorchã®ã‚«ã‚¹ã‚¿ãƒ æå¤±é–¢æ•°ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ã“ã®æå¤±é–¢æ•°ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¨ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®é †åºã‚’å¤‰æ›´ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’æ¯”è¼ƒã—ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒæ­£ã—ããªã„å ´åˆã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸Žãˆã¾ã™ã€‚\n",
    "\n",
    "ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ï¼š\n",
    "\n",
    "MultiElementRankLoss ã‚¯ãƒ©ã‚¹:\n",
    "ç›®çš„: ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¨ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®é †åºã‚’å¤‰æ›´ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’æ¯”è¼ƒã—ã¦æå¤±ã‚’è¨ˆç®—ã™ã‚‹ã€‚\n",
    "\n",
    "init ãƒ¡ã‚½ãƒƒãƒ‰:\n",
    "å…¥åŠ›: margin ã¨ number_permutationsã€‚ å‡¦ç†: MarginRankingLoss ã‚’åˆæœŸåŒ–ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹ã€‚\n",
    "\n",
    "calculate_rank_loss ãƒ¡ã‚½ãƒƒãƒ‰:\n",
    "å…¥åŠ›: outputs, config_runtime, config_idxsã€‚ outputs: ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã€‚ config_runtime: å„ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€‚ config_idxs: å„ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚ å‡¦ç†: ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®é †åºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã¹æ›¿ãˆã¦ã€MarginRankingLoss ã‚’è¨ˆç®—ã™ã‚‹ã€‚ã“ã®ä¸¦ã¹æ›¿ãˆã¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ç²¾åº¦ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«è¡Œã‚ã‚Œã¾ã™ã€‚ å‡ºåŠ›: å„ãƒãƒƒãƒã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¹³å‡æå¤±ã€‚\n",
    "\n",
    "å…¥åŠ›: outputs, config_runtime, config_idxsã€‚ å‡¦ç†: æŒ‡å®šã•ã‚ŒãŸæ•°ã®é †åˆ—ã§ calculate_rank_loss ã‚’ç¹°ã‚Šè¿”ã—ã€å¹³å‡æå¤±ã‚’è¨ˆç®—ã™ã‚‹ã€‚ å‡ºåŠ›: æœ€çµ‚çš„ãªå¹³å‡æå¤±ã€‚ ã‚¯ãƒ©ã‚¹ã®å‹•ä½œ: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–: margin ã¨ number_permutations ã‚’æŒ‡å®šã—ã¦ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚margin ã¯ãƒžãƒ¼ã‚¸ãƒ³ãƒ©ãƒ³ã‚­ãƒ³ã‚°æå¤±ã®ãƒžãƒ¼ã‚¸ãƒ³ã€number_permutations ã¯é †åˆ—ã®æ•°ã§ã™ã€‚ æå¤±è¨ˆç®—: forward ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã“ã‚Œã«ã¯ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã€è¨­å®šã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€è¨­å®šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¿…è¦ã§ã™ã€‚ é †åˆ—ã¨æå¤±: calculate_rank_loss ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¨ãã®é †åˆ—ã‚’ä½¿ã£ã¦ãƒžãƒ¼ã‚¸ãƒ³ãƒ©ãƒ³ã‚­ãƒ³ã‚°æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚åŒã˜è¨­å®šã§æ¯”è¼ƒã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ã¯ãƒžã‚¹ã‚¯ã•ã‚Œã€æå¤±ã®è¨ˆç®—ã«ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚ å¹³å‡æå¤±: ã™ã¹ã¦ã®é †åˆ—ã«å¯¾ã™ã‚‹æå¤±ã®å¹³å‡ãŒæœ€çµ‚çš„ãªæå¤±ã¨ã—ã¦è¿”ã•ã‚Œã¾ã™ã€‚ ã“ã®ã‚«ã‚¹ã‚¿ãƒ æå¤±é–¢æ•°ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚’æ­£ã—ããƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã¨æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã¾ã™ã€‚\n",
    "\n",
    "\"\"\"\n",
    "#Metric\n",
    "class TileTopK(tm.Metric):\n",
    "    \n",
    "    higher_is_better = True\n",
    "    \n",
    "    def __init__(self, k:int=5) -> None:\n",
    "        super().__init__()\n",
    "        self.add_state(\"runtimes\", default=[], dist_reduce_fx=None)\n",
    "        self.k = k\n",
    "        \n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, config_attn_mask:torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Update the metric state\n",
    "        Args:\n",
    "            preds: Tensor of shape (bs, seq_len) with the predicted runtimes orders\n",
    "            target: Tensor of shape (bs, seq_len) with the target runtimes\n",
    "            config_attn_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "        \"\"\"\n",
    "        best_runtimes = torch.where(config_attn_mask==1, target, torch.tensor(float('inf'))).min(1).values\n",
    "        masked_preds = torch.where(config_attn_mask==1, preds, torch.tensor(float('inf')))\n",
    "        pred_bottomk_indices = torch.topk(masked_preds, k=self.k, largest=False).indices\n",
    "        bs = preds.shape[0]\n",
    "        bottom_k_positions = torch.stack([torch.arange(bs).repeat_interleave(self.k).to(config_attn_mask.device), pred_bottomk_indices.view(-1)])\n",
    "        predicted_runtimes = target[bottom_k_positions[0], bottom_k_positions[1]].view(bs,self.k)\n",
    "        best_predicted_runtimes = predicted_runtimes.min(1).values\n",
    "        self.runtimes.append(best_predicted_runtimes/ best_runtimes)\n",
    "        \n",
    "    def compute(self) -> torch.Tensor:\n",
    "        return (2-torch.cat(self.runtimes)).mean()\n",
    "\"\"\"\n",
    "ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’æ¯”è¼ƒã—ã¦ã€ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®äºˆæ¸¬ã®æ­£ç¢ºã•ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€Top-K ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸãƒˆãƒƒãƒ—Kã®è¨­å®šã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨ã€å®Ÿéš›ã®æœ€é©ãªãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚\n",
    "\n",
    "TileTopK ã‚¯ãƒ©ã‚¹ã®èª¬æ˜Žï¼š\n",
    "\n",
    "å±žæ€§ã¨ãƒ¡ã‚½ãƒƒãƒ‰:\n",
    "higher_is_better: ã“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒé«˜ã„ã»ã©è‰¯ã„ã€ã¨ã„ã†æ„å‘³ã§Trueã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ init ãƒ¡ã‚½ãƒƒãƒ‰: åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã§ã€Top-Kã®Kã®å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚ update ãƒ¡ã‚½ãƒƒãƒ‰: äºˆæ¸¬ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€ãŠã‚ˆã³è¨­å®šã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒžã‚¹ã‚¯ã‚’å–å¾—ã—ã¦ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã™ã€‚ compute ãƒ¡ã‚½ãƒƒãƒ‰: ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çŠ¶æ…‹ã‹ã‚‰æœ€çµ‚çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "\n",
    "update ãƒ¡ã‚½ãƒƒãƒ‰ã®å‹•ä½œ:\n",
    "å…¥åŠ›: preds: ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®é †åºã€‚ target: å®Ÿéš›ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ç›®æ¨™å€¤ã€‚ config_attn_mask: ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã«1ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ä½ç½®ã«0ãŒå…¥ã£ãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒžã‚¹ã‚¯ã€‚\n",
    "\n",
    "å‡¦ç†: ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒžã‚¹ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã€æœ‰åŠ¹ãªè¨­å®šã®ä½ç½®ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®æœ€å°å€¤ï¼ˆæœ€é©ãªãƒ©ãƒ³ã‚¿ã‚¤ãƒ ï¼‰ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã†ã¡ã€Top-Kã®è¨­å®šã‚’é¸æŠžã—ã¾ã™ã€‚ é¸æŠžã•ã‚ŒãŸTop-Kè¨­å®šã®äºˆæ¸¬ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨å®Ÿéš›ã®æœ€é©ãªãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚ ã“ã®æ¯”è¼ƒã®çµæžœã‚’çŠ¶æ…‹ã«ä¿å­˜ã—ã¾ã™ã€‚\n",
    "\n",
    "compute ãƒ¡ã‚½ãƒƒãƒ‰ã®å‹•ä½œ:\n",
    "å‡¦ç†: update ãƒ¡ã‚½ãƒƒãƒ‰ã§ä¿å­˜ã•ã‚ŒãŸã™ã¹ã¦ã®æ¯”è¼ƒçµæžœã‹ã‚‰ã€æœ€çµ‚çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ å‡ºåŠ›: è¨ˆç®—ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å€¤ã‚’è¿”ã—ã¾ã™ã€‚ ä½¿ã„æ–¹ã®ã‚·ãƒŠãƒªã‚ªï¼š ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¾ãŸã¯è©•ä¾¡ä¸­ã«ã€ã“ã®TileTopKãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ äºˆæ¸¬ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ ãã‚Œãžã‚Œã®ãƒãƒƒãƒã§ã€updateãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ã€äºˆæ¸¬ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€ãŠã‚ˆã³è¨­å®šã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒžã‚¹ã‚¯ã‚’æ¸¡ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çŠ¶æ…‹ãŒæ›´æ–°ã•ã‚Œã¾ã™ã€‚ è©•ä¾¡ãŒå®Œäº†ã—ãŸã‚‰ã€computeãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ã€æœ€çµ‚çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å€¤ã‚’å–å¾—ã—ã¾ã™ã€‚ã“ã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ äºˆæ¸¬ã®æ€§èƒ½ã‚’ç¤ºã™å€¤ã«ãªã‚Šã¾ã™ã€‚ ã“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚Œã ã‘æ­£ç¢ºã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’äºˆæ¸¬ã§ãã‚‹ã‹ã€ç‰¹ã«ãƒˆãƒƒãƒ—Kã®è¨­å®šã«ç„¦ç‚¹ã‚’å½“ã¦ã¦è©•ä¾¡ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "#Model\n",
    "#Modified version of ðŸ¤— Bert implementation to take in to account Graph Attention\n",
    "#\n",
    "#Removed the parts corresponding to Cross-attention\n",
    "#Made layer_head_mask the same for all layers, heads\n",
    "#The Head mask corresponds to the edge adjacency\n",
    "# Modified from https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask #DONE: Same Head Mask for all layers\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs,  output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=None,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=None,\n",
    "        )\n",
    "        \n",
    "        \n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "    \n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "    \n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config:GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config, position_embedding_type=position_embedding_type)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config:GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = position_embedding_type or getattr(\n",
    "            config, \"position_embedding_type\", \"absolute\"\n",
    "        )\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
    "\n",
    "\n",
    "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        \n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
    "            position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "\n",
    "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask #DONE: Same Head Mask for all Heads\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "    \n",
    "class NodeEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.node_opcode_embeddings = nn.Embedding(NODE_OP_CODES+1 , config.embedding_size, padding_idx=NODE_OP_CODES)\n",
    "        self.linear = nn.Linear(NODE_FEATS, config.embedding_size, bias=False)\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)\n",
    "        \n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor,\n",
    "                node_feat: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        opcode_embeddings = self.node_opcode_embeddings(node_opcode) \n",
    "        node_feats =  self.linear(node_feat)\n",
    "        features = opcode_embeddings + node_feats\n",
    "        features = self.layer_norm(features)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "class BertNodeEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config:GraphConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_embeddings = NodeEncoder(config)\n",
    "        self.node_encoder = BertEncoder(config)\n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor,\n",
    "                node_feat: torch.Tensor,\n",
    "                edges_adjecency: torch.Tensor,\n",
    "                node_attn_mask: torch.Tensor\n",
    "                ):\n",
    "        node_embeddings = self.node_embeddings(node_opcode, node_feat)\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).unsqueeze(-1)\n",
    "        node_encoder_outputs = self.node_encoder(node_embeddings,\n",
    "                                                 attention_mask=node_attn_mask,\n",
    "                                                 head_mask=edges_adjecency.unsqueeze(0).repeat(self.config.num_hidden_layers, 1, 1, 1).unsqueeze(2),\n",
    "                                                 output_attentions=True)\n",
    "        return node_encoder_outputs\n",
    "    \n",
    "def transform_node_positional_embeddings(embeddings_output:torch.Tensor,\n",
    "                                         node_config_ids:torch.Tensor,\n",
    "                                         num_nodes:int\n",
    "                                         ) -> torch.Tensor:\n",
    "    bs, num_configs, _, dim = embeddings_output.shape\n",
    "    idxs = node_config_ids.unsqueeze(1).repeat(1,num_configs,1)\n",
    "    zeros = torch.zeros(bs, num_configs, num_nodes, dim, device=embeddings_output.device, dtype=embeddings_output.dtype)\n",
    "    idxs = idxs.unsqueeze(-1).repeat(1,1,1,dim)\n",
    "    zeros.scatter_reduce_(2, idxs, embeddings_output, reduce='sum')\n",
    "    return zeros\n",
    "\n",
    "class NodeFeatEmbeddings(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_feat_embeddings = nn.Linear(NODE_CONFIG_FEATS + CONFIG_FEATS, config.embedding_size, bias=False)\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)\n",
    "        \n",
    "    def forward(self, node_config_feat: torch.Tensor, node_config_ids: torch.Tensor, num_nodes:int) -> torch.Tensor:\n",
    "        node_config_feat_embeddings = self.node_feat_embeddings(node_config_feat)\n",
    "        node_config_feat_embeddings = self.layer_norm(node_config_feat_embeddings)\n",
    "        node_config_feat_embeddings = transform_node_positional_embeddings(node_config_feat_embeddings, node_config_ids, num_nodes)\n",
    "        return node_config_feat_embeddings\n",
    "        \n",
    "    \n",
    "class BertGraphEncoder(nn.Module):\n",
    "    def __init__(self, config:GraphConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_embeddings = NodeEncoder(config)\n",
    "        self.node_encoder = BertEncoder(config)\n",
    "        self.node_feat_embeddings = NodeFeatEmbeddings(config)\n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor, # (bs, num_nodes)\n",
    "                node_feat: torch.Tensor, # (bs, num_nodes, num_node_feats)\n",
    "                edges_adjecency: torch.Tensor, # (bs, num_nodes, num_nodes)\n",
    "                node_attn_mask: torch.Tensor, # (bs, num_nodes)\n",
    "                node_config_feat: torch.Tensor, # (bs, num_configs, num_config_nodes, num_node_feats)\n",
    "                node_config_ids: torch.Tensor, # (bs, num_configs, num_config_nodes)\n",
    "                ):\n",
    "        bs, num_nodes = node_opcode.shape\n",
    "        num_configs = node_config_feat.shape[1]\n",
    "        node_embeddings = self.node_embeddings(node_opcode, node_feat)\n",
    "        node_config_feat_embeddings = self.node_feat_embeddings(node_config_feat, node_config_ids, num_nodes)\n",
    "        \n",
    "        node_embeddings = node_embeddings.unsqueeze(1).repeat(1, num_configs, 1, 1)\n",
    "        node_embeddings += node_config_feat_embeddings\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).repeat(1, num_configs, 1)\n",
    "        node_embeddings = node_embeddings.reshape(bs *num_configs, num_nodes, -1)\n",
    "        node_attn_mask = node_attn_mask.reshape(bs *num_configs, num_nodes)\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).unsqueeze(-1)\n",
    "        edges_adjecency = edges_adjecency.unsqueeze(1).repeat(1, num_configs, 1, 1).reshape(bs *num_configs, num_nodes, num_nodes)\n",
    "        edges_adjecency = edges_adjecency.unsqueeze(1)\n",
    "        \n",
    "\n",
    "        node_encoder_outputs = self.node_encoder(node_embeddings,\n",
    "                                                 attention_mask=node_attn_mask,\n",
    "                                                 head_mask=edges_adjecency,\n",
    "                                                 output_attentions=True)\n",
    "        \n",
    "        return node_encoder_outputs.last_hidden_state.reshape(bs, num_configs, num_nodes, -1)\n",
    "    \n",
    "    \n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    config_class = GraphConfig\n",
    "    \n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_encoder = BertGraphEncoder(config)\n",
    "        self.head = nn.Linear(config.hidden_size, 1)\n",
    "        self.loss_fn = MultiElementRankLoss(margin=config.margin, number_permutations=config.number_permutations)\n",
    "        \n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor, # (bs, num_nodes)\n",
    "                node_feat: torch.Tensor, # (bs, num_nodes, num_node_feats)\n",
    "                edges_adjecency: torch.Tensor, # (bs, num_nodes, num_nodes)\n",
    "                node_attn_mask: torch.Tensor, # (bs, num_nodes)\n",
    "                node_config_feat: torch.Tensor, # (bs, num_configs, num_config_nodes, num_node_feats)\n",
    "                node_config_ids: torch.Tensor, # (bs, num_configs, num_config_nodes)\n",
    "                config_idxs: Optional[torch.Tensor] = None, # (bs, num_configs)\n",
    "                config_runtime: Optional[torch.Tensor] = None,):\n",
    "        \n",
    "        last_hidden_state = self.node_encoder(node_opcode,\n",
    "                                    node_feat,\n",
    "                                    edges_adjecency,\n",
    "                                    node_attn_mask,\n",
    "                                    node_config_feat,\n",
    "                                    node_config_ids)\n",
    "        \n",
    "        output = self.head(last_hidden_state[:,:,0]).squeeze(-1)\n",
    "        outputs = {'outputs': output, 'order': torch.argsort(output, dim=1)}\n",
    "        if config_runtime is not None:\n",
    "            loss = 0\n",
    "            loss += self.loss_fn(output, config_runtime, config_idxs)\n",
    "            outputs['loss'] = loss\n",
    "        return outputs\n",
    "\"\"\"\n",
    "ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«BERTãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆ©ç”¨ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã‚’å‡¦ç†ã—ã¦ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚’åˆ©ç”¨ã—ã¦ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ï¼ˆã“ã“ã§ã¯è¨­å®šã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’äºˆæ¸¬ã™ã‚‹ï¼‰ã®ãŸã‚ã®å‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã§æ§‹æˆã•ã‚Œã€å¤§é‡ã®æƒ…å ±ã‚’å«ã‚“ã§ã„ã‚‹ãŸã‚ã€ä»¥ä¸‹ã«ä¸»è¦ãªéƒ¨åˆ†ã‚’åˆ†è§£ã—ã¦èª¬æ˜Žã—ã¾ã™ã€‚\n",
    "\n",
    "BertEncoder ã‚¯ãƒ©ã‚¹ ç›®çš„: BERTãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ï¼‰ã‚’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å½¹å‰²ã‚’æžœãŸã—ã¾ã™ã€‚ ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å‡¦ç†ã‚’è¡Œã„ã€ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã€æ³¨æ„ã®é‡ã¿ã€éš ã‚ŒçŠ¶æ…‹ãªã©ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "BertLayer ãŠã‚ˆã³ãã®é–¢é€£ã‚¯ãƒ©ã‚¹ (BertIntermediate, BertOutput, BertAttention, BertSelfAttention, BertSelfOutput) ç›®çš„: BERTã®å†…éƒ¨å±¤ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ãã‚Œãžã‚Œã®ã‚¯ãƒ©ã‚¹ã¯ã€BERTã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€æ­£è¦åŒ–ã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãªã©ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¡¨ç¾ã—ã¦ã„ã¾ã™ã€‚ ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: å„ã‚¯ãƒ©ã‚¹ã¯ forward ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ãã‚Œãžã‚Œã®éƒ¨åˆ†ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "NodeEncoder ã‚¯ãƒ©ã‚¹ ç›®çš„: ã‚°ãƒ©ãƒ•ã®ãƒŽãƒ¼ãƒ‰æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã§ã™ã€‚ãƒŽãƒ¼ãƒ‰ã®ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã¨ç‰¹å¾´ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã€ãã‚Œãžã‚Œã®ãƒŽãƒ¼ãƒ‰ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒŽãƒ¼ãƒ‰ã®ã‚ªãƒšã‚³ãƒ¼ãƒ‰ã¨ç‰¹å¾´ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "BertNodeEncoder ã‚¯ãƒ©ã‚¹ ç›®çš„: NodeEncoder ã¨ BertEncoder ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ã‚°ãƒ©ãƒ•ã®ãƒŽãƒ¼ãƒ‰ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹ã§ã™ã€‚ ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã¨æ³¨æ„ã®é‡ã¿ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "transform_node_positional_embeddings é–¢æ•° ã“ã®é–¢æ•°ã¯ã€ãƒŽãƒ¼ãƒ‰ã®ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’å¤‰æ›ã™ã‚‹å½¹å‰²ã‚’æžœãŸã—ã¦ã„ã¾ã™ã€‚\n",
    "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: embeddings_output: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰ã®å‡ºåŠ›ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã€‚ node_config_ids: ãƒŽãƒ¼ãƒ‰ã®è¨­å®šIDã€‚ num_nodes: ãƒŽãƒ¼ãƒ‰ã®åˆè¨ˆæ•°ã€‚ å‹•ä½œ: bs, numconfigs, , dim å¤‰æ•°ã¯ã€ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã®å‡ºåŠ›å½¢çŠ¶ã‹ã‚‰å¾—ã‚‰ã‚Œã¾ã™ã€‚bs ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã€num_configs ã¯è¨­å®šã®æ•°ã€dim ã¯ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã®æ¬¡å…ƒã§ã™ã€‚ idxs å¤‰æ•°ã¯ã€ãƒŽãƒ¼ãƒ‰è¨­å®šIDã‚’ç”¨ã„ã¦ã€å„ãƒŽãƒ¼ãƒ‰ã®ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ zeros ã¯ã€å¤‰æ›å¾Œã®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®ã‚¼ãƒ­ãƒ†ãƒ³ã‚½ãƒ«ã§ã™ã€‚ æœ€å¾Œã« scatterreduce ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ã€embeddings_output ã‹ã‚‰ãƒŽãƒ¼ãƒ‰ã®ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—ã—ã€zeros ãƒ†ãƒ³ã‚½ãƒ«ã«æ ¼ç´ã—ã¾ã™ã€‚\n",
    "\n",
    "NodeFeatEmbeddings ã‚¯ãƒ©ã‚¹ ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€ãƒŽãƒ¼ãƒ‰ã¨ãã®ç‰¹å¾´ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’å«ã‚€ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒŽãƒ¼ãƒ‰ã®è¨­å®šç‰¹å¾´ã¨IDã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚transform_node_positional_embeddings é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "BertGraphEncoder ã‚¯ãƒ©ã‚¹ ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å…¨ä½“ã‚’æ‹…å½“ã—ã¾ã™ã€‚ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã€ãƒŽãƒ¼ãƒ‰ã®ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ãªã©ã‚’å‡¦ç†ã—ã€ã‚°ãƒ©ãƒ•ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã€ãƒŽãƒ¼ãƒ‰ã®è¨­å®šæƒ…å ±ãªã©ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã®ã‚¯ãƒ©ã‚¹ã§ã¯ã€ãƒŽãƒ¼ãƒ‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ä½ç½®ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã®ä¸¡æ–¹ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "GraphEncoder ã‚¯ãƒ©ã‚¹ ã“ã‚Œã¯ã€ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã€ãã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åŸºã«ã—ãŸãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã§ã™ã€‚\n",
    "ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰: forward ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ã‚°ãƒ©ãƒ•ã®ãƒŽãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã€ãƒŽãƒ¼ãƒ‰ã®è¨­å®šæƒ…å ±ã€ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãªã©ã‚’å—ã‘å–ã‚Šã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚ã¾ãŸã€å¿…è¦ã«å¿œã˜ã¦ã€æå¤±ã‚‚è¨ˆç®—ã—ã¾ã™ã€‚ ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€å…ˆã«èª¬æ˜Žã—ãŸBertGraphEncoderã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ã‚°ãƒ©ãƒ•ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€MultiElementRankLossæå¤±é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®äºˆæ¸¬ã®ãŸã‚ã®æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "\n",
    "class LightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.topk = TileTopK()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.model(**batch)\n",
    "        return outputs['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.model(**batch)\n",
    "        loss = outputs['loss']\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        config_attn_mask = torch.ones_like(batch['config_runtime'], device=batch['config_runtime'].device)\n",
    "        self.topk.update(outputs['outputs'], batch['config_runtime'], config_attn_mask)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        topk = self.topk.compute()\n",
    "        self.print(f\"topk {topk:.3f}\")\n",
    "        self.topk.reset()\n",
    "        return super().on_validation_end()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.model.loss(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.trainer.model.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\"\"\"\n",
    "LightningWrapper ã‚¯ãƒ©ã‚¹ã®æ§‹é€ \n",
    "\n",
    "init ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨Top-Kè©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¨ã—ã¦ä¿æŒã—ã¾ã™ã€‚\n",
    "\n",
    "model: ã“ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¯ã€è¨“ç·´ã€æ¤œè¨¼ã€ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒã—ã¾ã™ã€‚ topk: ã“ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¯ã€æ¤œè¨¼ã®éš›ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®Top-Kãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä¿æŒã—ã¾ã™ã€‚\n",
    "\n",
    "forward ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€å…¥åŠ›xã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã¦ã€å‡ºåŠ›ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "\n",
    "training_step ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å„è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã§å‘¼ã³å‡ºã•ã‚Œã€ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹è¨“ç·´ã®æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã¯batchå¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚Œã€æå¤±ã¯ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚\n",
    "\n",
    "validation_step ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å„æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—ã§å‘¼ã³å‡ºã•ã‚Œã€ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¤œè¨¼ã®æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€Top-Kãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§è¨ˆç®—ã•ã‚Œã€æ›´æ–°ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "loss: æ¤œè¨¼ã®æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ self.log: æ¤œè¨¼ã®æå¤±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¾ã™ã€‚ config_attn_mask: è¨­å®šã®æ³¨ç›®ãƒžã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã™ã€‚ self.topk.update: Top-Kãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’æ›´æ–°ã—ã¾ã™ã€‚\n",
    "\n",
    "on_validation_end ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "æ¤œè¨¼ãŒçµ‚äº†ã—ãŸã¨ãã«å‘¼ã³å‡ºã•ã‚Œã€Top-Kãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å€¤ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚ãã®å¾Œã€Top-Kãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚\n",
    "\n",
    "test_step ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ãƒ†ã‚¹ãƒˆã‚¹ãƒ†ãƒƒãƒ—ã§å‘¼ã³å‡ºã•ã‚Œã€ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã®æå¤±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "\n",
    "configure_optimizers ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "ã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ã‚’è¨­å®šã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã§ã™ã€‚ã“ã®ä¾‹ã§ã¯ã€AdamWã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’çŽ‡ã¯0.001ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "LightningWrapper ã‚¯ãƒ©ã‚¹ã¯ã€ã‚°ãƒ©ãƒ•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¢ãƒ‡ãƒ«ã‚’PyTorch Lightningãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã£ã¦åŠ¹çŽ‡çš„ã«è¨“ç·´ã€æ¤œè¨¼ã€ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã§ã™ã€‚è¨“ç·´ã¨æ¤œè¨¼ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æå¤±ã‚’è¨ˆç®—ã—ã€æ¤œè¨¼ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚‚è¨ˆç®—ã—ã¾ã™ã€‚ã¾ãŸã€ã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ã®è¨­å®šã‚„ãƒ†ã‚¹ãƒˆã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\"\"\"\n",
    "#Training\n",
    "\n",
    "config_kwargs = dict(hidden_size= 128,\n",
    "    num_attention_heads= 4,\n",
    "    num_hidden_layers= 2,\n",
    "    intermediate_size= 64,\n",
    "    gradient_checkpointing= True,\n",
    "    margin= 0.1,\n",
    "    number_permutations= 4,\n",
    "    )\n",
    "config = GraphConfig(**config_kwargs)\n",
    "model = GraphEncoder(config)\n",
    "model = LightningWrapper(model)\n",
    "tile_df\n",
    "\"\"\"\n",
    "paths\tsplit\tconfiguration\textra\tmodel_name\tcollection\tID\n",
    "0\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tresnet_v1_50_official_batch_128_bf16_2bea628b7...\ttile:xla\ttile:xla:resnet_v1_50_official_batch_128_bf16_...\n",
    "1\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_40fa8f86f121f00a\ttile:xla\ttile:xla:inception_v3_batch_128_train_40fa8f86...\n",
    "2\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_-23e94c034a65a177\ttile:xla\ttile:xla:inception_v3_batch_128_train_-23e94c0...\n",
    "3\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tinception_v3_batch_128_train_171f4371caf28639\ttile:xla\ttile:xla:inception_v3_batch_128_train_171f4371...\n",
    "4\t../input/predict-ai-model-runtime/npz_all/npz/...\tvalid\txla\ttile\tmlperf_bert_batch_24_2x2_-25e30862c042a2b8\ttile:xla\ttile:xla:mlperf_bert_batch_24_2x2_-25e30862c04...\n",
    "...\t...\t...\t...\t...\t...\t...\t...\n",
    "7224\t../input/predict-ai-model-runtime/npz_all/npz/...\ttrain\txla\ttile\tshapemask.4x4.fp32_-308d824e29eea7d5\ttile:xla\ttile:xla:shapemask.4x4.fp32_-308d824e29eea7d5\n",
    "7225\t../input/predict-ai-model-runtime/npz_all/npz/...\ttrain\txla\ttile\tmnasnet_b1_batch_128_274248815373b90a\ttile:xla\ttile:xla:mnasnet_b1_batch_128_274248815373b90a\n",
    "7226\t../input/predict-ai-model-runtime/npz_all/npz/...\ttrain\txla\ttile\tshapemask.4x4.fp32_15c8ed14770f4c5e\ttile:xla\ttile:xla:shapemask.4x4.fp32_15c8ed14770f4c5e\n",
    "7227\t../input/predict-ai-model-runtime/npz_all/npz/...\ttrain\txla\ttile\tinception_v2_batch_8_train_-2780d93f2933627\ttile:xla\ttile:xla:inception_v2_batch_8_train_-2780d93f2...\n",
    "7228\t../input/predict-ai-model-runtime/npz_all/npz/...\ttrain\txla\ttile\tretinanet.4x4.fp32_-5ad42689cc8da2aa\ttile:xla\ttile:xla:retinanet.4x4.fp32_-5ad42689cc8da2aa\n",
    "7229 rows Ã— 7 columns\n",
    "\"\"\"\n",
    "train_df = tile_df.query(\"split == 'train'\").reset_index(drop=True)\n",
    "valid_df = tile_df.query(\"split == 'valid'\").reset_index(drop=True)\n",
    "train_dataset = TileDataset(train_df, num_configs=24)\n",
    "valid_dataset = TileDataset(valid_df, num_configs=24)\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=8, num_workers=2, shuffle=True, persistent_workers=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, collate_fn=collate_fn, batch_size=8, num_workers=2)\n",
    "trainer_config = dict(\n",
    "    max_epochs= 50,\n",
    "    precision= 32,\n",
    "    gradient_clip_val= 1.0,\n",
    "    accumulate_grad_batches= 4,\n",
    "    check_val_every_n_epoch= 10)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer = pl.Trainer(**trainer_config,)\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)\n",
    "\"\"\"\n",
    "Epoch 49: 100%\n",
    "714/714 [00:33<00:00, 21.61it/s, v_num=0, val_loss=0.0322]\n",
    "topk 0.982\n",
    "topk 0.983\n",
    "topk 0.986\n",
    "topk 0.987\n",
    "topk 0.991\n",
    "\"\"\"\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "split = 'test'\n",
    "test_tile_df = tile_df.query(\"split == @split\").reset_index(drop=True)\n",
    "test_tile_ds = TileDataset(test_tile_df, num_configs=-1)\n",
    "collate_fn = LayoutCollator(64, targets=split!=\"test\")\n",
    "test_dataloader = DataLoader(test_tile_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "def chunk_batch(batch, start_idx, end_idx):\n",
    "    output = {k:batch[k] for k in ['node_opcode', 'node_feat', 'edges_adjecency', 'node_attn_mask', 'node_config_ids']}\n",
    "    output['node_config_feat'] = batch['node_config_feat'][:, start_idx: end_idx]\n",
    "    return output\n",
    "    \n",
    "pred_order = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch.pop('config_idxs')\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    num_configs = batch['node_config_feat'].shape[1]\n",
    "    # Chunk the configs to avoid OOM errors\n",
    "    configs_cut_points = list(range(0,num_configs, 100)) + [num_configs]\n",
    "    chunk_order = []\n",
    "    for start, end in zip(configs_cut_points, configs_cut_points[1:]):\n",
    "        chunked_batch = chunk_batch(batch, start, end)\n",
    "        with torch.no_grad():\n",
    "            output = model.model(**chunked_batch)\n",
    "        chunk_order.extend(output['outputs'].cpu().numpy())\n",
    "    pred_order.append(np.argsort(np.concatenate(chunk_order))[:5])\n",
    "\"\"\"\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [01:18<00:00, 10.81it/s]\n",
    "\"\"\"\n",
    "idxs_string = [\";\".join(map(str,elem)) for elem in pred_order]\n",
    "test_tile_df['TopConfigs'] = idxs_string\n",
    "test_tile_df = test_tile_df[['ID', 'TopConfigs']]\n",
    "test_tile_df.head()\n",
    "\"\"\"\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:04ae9238c653f8ae08f60f2c03615f0b\t273;299;479;661;385\n",
    "1\ttile:xla:85d157d3b1848c6b6fff0c633876e2e6\t6792;8019;7513;2902;3531\n",
    "2\ttile:xla:862900d42397d03be2762e1bf7518bea\t206;161;1409;287;1344\n",
    "3\ttile:xla:0afa527a7022415fda1dd69d11e908a4\t158;210;212;69;20\n",
    "4\ttile:xla:2d09e3ab92e184c561abaf8d9efe7b87\t170;147;24;89;6\n",
    "\"\"\"\n",
    "submission_df = pd.read_csv('../input/predict-ai-model-runtime/sample_submission.csv')\n",
    "submission_df = submission_df.query(f\"ID not in {test_tile_df.ID.tolist()}\")\n",
    "submission_df = pd.concat([test_tile_df, submission_df])\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df\n",
    "\"\"\"\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:04ae9238c653f8ae08f60f2c03615f0b\t273;299;479;661;385\n",
    "1\ttile:xla:85d157d3b1848c6b6fff0c633876e2e6\t6792;8019;7513;2902;3531\n",
    "2\ttile:xla:862900d42397d03be2762e1bf7518bea\t206;161;1409;287;1344\n",
    "3\ttile:xla:0afa527a7022415fda1dd69d11e908a4\t158;210;212;69;20\n",
    "4\ttile:xla:2d09e3ab92e184c561abaf8d9efe7b87\t170;147;24;89;6\n",
    "...\t...\t...\n",
    "889\tlayout:nlp:random:60880ed76de53f4d7a1b960b24f2...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "890\tlayout:nlp:random:23559853d9702baaaacbb0c83fd3...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "891\tlayout:nlp:random:f6c146fc5cf10be4f3accbaca989...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "892\tlayout:nlp:random:32531d07a084b319dce484f53a4c...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "893\tlayout:nlp:random:3a0c5517a87df8d82fd637b83298...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "894 rows Ã— 2 columns\n",
    "\"\"\"\n",
    "\n",
    "!pip install /kaggle/input/fast-slow-4-dataset-train/torch_geometric-2.3.1-py3-none-any.whl\n",
    "!pip install /kaggle/input/fast-slow-4-dataset-train/torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\n",
    "\"\"\"\n",
    "Processing /kaggle/input/fast-slow-4-dataset-train/torch_geometric-2.3.1-py3-none-any.whl\n",
    "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (4.66.1)\n",
    "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.23.5)\n",
    "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.11.2)\n",
    "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.1.2)\n",
    "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (2.31.0)\n",
    "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (3.0.9)\n",
    "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (1.2.2)\n",
    "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric==2.3.1) (5.9.3)\n",
    "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric==2.3.1) (2.1.3)\n",
    "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.1.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (3.4)\n",
    "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (1.26.15)\n",
    "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric==2.3.1) (2023.7.22)\n",
    "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (1.3.2)\n",
    "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric==2.3.1) (3.1.0)\n",
    "Installing collected packages: torch-geometric\n",
    "Successfully installed torch-geometric-2.3.1\n",
    "Processing /kaggle/input/fast-slow-4-dataset-train/torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl\n",
    "Installing collected packages: torch-scatter\n",
    "Successfully installed torch-scatter-2.1.1\n",
    "!pip install timm\n",
    "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.7)\n",
    "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.0.0)\n",
    "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.15.1)\n",
    "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\n",
    "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.4)\n",
    "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.3.3)\n",
    "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.12.2)\n",
    "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.6.3)\n",
    "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\n",
    "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\n",
    "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n",
    "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2023.9.0)\n",
    "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n",
    "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\n",
    "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\n",
    "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\n",
    "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\n",
    "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
    "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
    "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.1.0)\n",
    "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
    "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
    "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
    "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
    "\"\"\"\n",
    "import timm\n",
    "from timm.scheduler import  CosineLRScheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "import sklearn,sklearn.model_selection\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from timm.scheduler import CosineLRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cpu'\n",
    "def load_df(directory):\n",
    "    splits = [\"test\"]\n",
    "    dfs = dict()\n",
    "    \n",
    "    for split in splits:\n",
    "        path = os.path.join(directory, split)\n",
    "        files = os.listdir(path)\n",
    "        list_df = []\n",
    "        \n",
    "        for file in files:\n",
    "            d = dict(np.load(os.path.join(path,file)))\n",
    "            d['file'] = file\n",
    "            list_df.append(d)\n",
    "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
    "    return dfs\n",
    "layout_xla_random = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/random/\")\n",
    "layout_xla_default = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/xla/default/\")\n",
    "layout_nlp_default = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/default/\")\n",
    "layout_nlp_random = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout/nlp/random/\")\n",
    "class TileDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        config_feat = torch.tensor(row['node_config_feat'].astype(np.float32))\n",
    "        node_feat = torch.tensor(row['node_feat'].astype(np.float32))\n",
    "        node_opcode = torch.tensor(row['node_opcode'].astype(np.int64))\n",
    "        edge_index = torch.tensor(np.swapaxes(row['edge_index'],0,1).astype(np.int64))\n",
    "        target = (row['config_runtime']).astype(np.float32)\n",
    "        # minmax scale the target, we only care about order\n",
    "        target = (target-min(target))/(max(target) -min(target))\n",
    "        target = torch.tensor(target)\n",
    "        return config_feat,node_feat,node_opcode,edge_index,target\n",
    "    \n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, graph_feats, hidden_dim):\n",
    "        super().__init__()\n",
    "        op_embedding_dim = 4 # I choose 4-dimensional embedding\n",
    "        self.embedding = torch.nn.Embedding(120, #120 different op-codes\n",
    "                                            op_embedding_dim,\n",
    "                                           )\n",
    "        assert len(hidden_channels)>0\n",
    "        in_channels = op_embedding_dim+140\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        last_dim = hidden_channels[0]\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels[0]))\n",
    "        for i in range(len(hidden_channels)-1):\n",
    "            self.convs.append(GCNConv(hidden_channels[i], hidden_channels[i+1]))\n",
    "            last_dim = hidden_channels[i+1]\n",
    "        self.convs.append(GCNConv(last_dim, graph_feats))\n",
    "        \n",
    "        self.dense = torch.nn.Sequential(nn.Linear(82, 64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(64, 64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(64, 1),\n",
    "                                        )\n",
    "    \n",
    "    def forward(self, x_cfg: Tensor,x_feat: Tensor, x_op: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        \n",
    "        #get graph features\n",
    "        x_cfg = x_cfg.mean(dim=1)\n",
    "        #print(x_cfg.shape)\n",
    "        x = torch.concat([x_feat,self.embedding(x_op)],dim = 1)\n",
    "        #pass though conv layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        # get 1d graph embedding using average pooling\n",
    "        x_graph = torch.mean(x,0)\n",
    "        \n",
    "        \n",
    "        #put graph data into config data\n",
    "        x = torch.concat([x_cfg,x_graph.repeat((len(x_cfg),1))],axis=1) #torch.Size([10528, 225])\n",
    "        #put into dense nn\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(self.dense(x))\n",
    "        return x\n",
    "\n",
    "model = SimpleModel(hidden_channels = [16,32,16,48],graph_feats = 64,hidden_dim=64).to(device)\n",
    "class SimpleModel2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, graph_feats, hidden_dim):\n",
    "        super().__init__()\n",
    "        op_embedding_dim = 4 # I choose 4-dimensional embedding\n",
    "        self.embedding = torch.nn.Embedding(120, #120 different op-codes\n",
    "                                            op_embedding_dim,\n",
    "                                           )\n",
    "        assert len(hidden_channels)>0\n",
    "        in_channels = op_embedding_dim+140\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        last_dim = hidden_channels[0]\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels[0]))\n",
    "        for i in range(len(hidden_channels)-1):\n",
    "            self.convs.append(SAGEConv(hidden_channels[i], hidden_channels[i+1]))\n",
    "            last_dim = hidden_channels[i+1]\n",
    "        self.convs.append(SAGEConv(last_dim, graph_feats))\n",
    "        \n",
    "        self.dense = torch.nn.Sequential(nn.Linear(82, 64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(64, 64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(64, 1),\n",
    "                                        )\n",
    "    \n",
    "    def forward(self, x_cfg: Tensor,x_feat: Tensor, x_op: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        \n",
    "        #get graph features\n",
    "        x_cfg = x_cfg.mean(dim=1)\n",
    "        #print(x_cfg.shape)\n",
    "        x = torch.concat([x_feat,self.embedding(x_op)],dim = 1)\n",
    "        #pass though conv layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        # get 1d graph embedding using average pooling\n",
    "        x_graph = torch.mean(x,0)\n",
    "        \n",
    "        \n",
    "        #put graph data into config data\n",
    "        x = torch.concat([x_cfg,x_graph.repeat((len(x_cfg),1))],axis=1) #torch.Size([10528, 225])\n",
    "        #put into dense nn\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(self.dense(x))\n",
    "        return x\n",
    "\n",
    "model2 = SimpleModel2(hidden_channels = [16,32,16,48],graph_feats = 64,hidden_dim=64).to(device)\n",
    "dataset = TileDataset(layout_xla_default[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(5):\n",
    "    model.load_state_dict(torch.load(f'/kaggle/input/fast-slow-sep/xla_defalut/layout_xla_default_best_model_{fold}.pth',map_location=torch.device('cpu') ))\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "        tile_xla_predictions[i].append(out.cpu().detach().numpy())\n",
    "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:-1] for pred in tile_xla_predictions]\n",
    "tile_xla_predictions[0]\n",
    "#sub = submission_df\n",
    "sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
    "for i,filename in enumerate(layout_xla_random[\"test\"]['file'].values):\n",
    "    id = 'layout:xla:default:' +filename[:-4]\n",
    "    print(id)\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub\n",
    "\"\"\"\n",
    "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_23/1750813363.py:16: RuntimeWarning: invalid value encountered in divide\n",
    "  target = (target-min(target))/(max(target) -min(target))\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.14it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.45it/s]\n",
    "layout:xla:default:cd708819d3f5103afd6460b15e74eaf3\n",
    "layout:xla:default:05ae41e26dd3c4c06390371a0423233c\n",
    "layout:xla:default:e8a3a1401b5e79f66d7037e424f3b6df\n",
    "layout:xla:default:fbaa8bb6a1aed9988281085c91065c05\n",
    "layout:xla:default:937ee0eb0d5d6151b7b8252933b5c1c9\n",
    "layout:xla:default:3e7156ac468dfb75cf5c9615e1e5887d\n",
    "layout:xla:default:5335ed13823b0a518ee3c79ba4425f34\n",
    "layout:xla:default:db59a991b7c607634f13570d52ce885f\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:d6f5f54247bd1e58a10b9e7062c636ab\t0;1;2;3;4\n",
    "1\ttile:xla:e3a655daa38e34ec240df959b650ac16\t0;1;2;3;4\n",
    "2\ttile:xla:f8c2c1a1098b2a361c26df668b286c87\t0;1;2;3;4\n",
    "3\ttile:xla:4dd1716853ed46ee4e7d09ede1732de8\t0;1;2;3;4\n",
    "4\ttile:xla:d0a69155b6340748c36724e4bfc34be3\t0;1;2;3;4\n",
    "...\t...\t...\n",
    "889\tlayout:nlp:random:60880ed76de53f4d7a1b960b24f2...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "890\tlayout:nlp:random:23559853d9702baaaacbb0c83fd3...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "891\tlayout:nlp:random:f6c146fc5cf10be4f3accbaca989...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "892\tlayout:nlp:random:32531d07a084b319dce484f53a4c...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "893\tlayout:nlp:random:3a0c5517a87df8d82fd637b83298...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "894 rows Ã— 2 columns\n",
    "\"\"\"\n",
    "dataset = TileDataset(layout_xla_random[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(5):\n",
    "    model.load_state_dict(torch.load(f'/kaggle/input/fast-slow-sep/xla_random/layout_xla_default_best_model_{fold}.pth',map_location=torch.device('cpu') ))\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind)\n",
    "        tile_xla_predictions[i].append(out.cpu().detach().numpy())\n",
    "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:-1] for pred in tile_xla_predictions]\n",
    "tile_xla_predictions[0]\n",
    "\n",
    "#sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
    "for i,filename in enumerate(layout_xla_random[\"test\"]['file'].values):\n",
    "    id = 'layout:xla:random:' +filename[:-4]\n",
    "    print(id)\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub\n",
    "\"\"\"\n",
    "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_23/1750813363.py:16: RuntimeWarning: invalid value encountered in divide\n",
    "  target = (target-min(target))/(max(target) -min(target))\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.35it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.33it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.74it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.69it/s]\n",
    "layout:xla:random:cd708819d3f5103afd6460b15e74eaf3\n",
    "layout:xla:random:05ae41e26dd3c4c06390371a0423233c\n",
    "layout:xla:random:e8a3a1401b5e79f66d7037e424f3b6df\n",
    "layout:xla:random:fbaa8bb6a1aed9988281085c91065c05\n",
    "layout:xla:random:937ee0eb0d5d6151b7b8252933b5c1c9\n",
    "layout:xla:random:3e7156ac468dfb75cf5c9615e1e5887d\n",
    "layout:xla:random:5335ed13823b0a518ee3c79ba4425f34\n",
    "layout:xla:random:db59a991b7c607634f13570d52ce885f\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:d6f5f54247bd1e58a10b9e7062c636ab\t0;1;2;3;4\n",
    "1\ttile:xla:e3a655daa38e34ec240df959b650ac16\t0;1;2;3;4\n",
    "2\ttile:xla:f8c2c1a1098b2a361c26df668b286c87\t0;1;2;3;4\n",
    "3\ttile:xla:4dd1716853ed46ee4e7d09ede1732de8\t0;1;2;3;4\n",
    "4\ttile:xla:d0a69155b6340748c36724e4bfc34be3\t0;1;2;3;4\n",
    "...\t...\t...\n",
    "889\tlayout:nlp:random:60880ed76de53f4d7a1b960b24f2...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "890\tlayout:nlp:random:23559853d9702baaaacbb0c83fd3...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "891\tlayout:nlp:random:f6c146fc5cf10be4f3accbaca989...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "892\tlayout:nlp:random:32531d07a084b319dce484f53a4c...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "893\tlayout:nlp:random:3a0c5517a87df8d82fd637b83298...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "894 rows Ã— 2 columns\n",
    "\"\"\"\n",
    "dataset = TileDataset(layout_nlp_default[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(5):\n",
    "    model.load_state_dict(torch.load(f'/kaggle/input/fast-slow-nlp-v3/nlp_default/layout_xla_default_best_model_{fold}.pth',map_location=torch.device('cpu') ))\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind) \n",
    "        tile_xla_predictions[i].append(out.cpu().detach().numpy())\n",
    "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:-1] for pred in tile_xla_predictions]\n",
    "tile_xla_predictions[0]\n",
    "\n",
    "#sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
    "for i,filename in enumerate(layout_nlp_default[\"test\"]['file'].values):\n",
    "    id = 'layout:nlp:default:' +filename[:-4]\n",
    "    print(id)\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub\n",
    "\"\"\"\n",
    "  0%|          | 0/17 [00:00<?, ?it/s]/tmp/ipykernel_23/1750813363.py:16: RuntimeWarning: invalid value encountered in divide\n",
    "  target = (target-min(target))/(max(target) -min(target))\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 42.06it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 40.82it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 33.71it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 36.62it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 42.31it/s]\n",
    "layout:nlp:default:b2fdde3b72980907578648774101543e\n",
    "layout:nlp:default:29886a50d55cfe77a9497bc906c76ce9\n",
    "layout:nlp:default:7105451001e119f65b66570d170b94a8\n",
    "layout:nlp:default:171b0513d8874a427ccfa46d136fbadc\n",
    "layout:nlp:default:60880ed76de53f4d7a1b960b24f20f7d\n",
    "layout:nlp:default:58cc2e418c3a8a19b871e15964b534ad\n",
    "layout:nlp:default:f6c146fc5cf10be4f3accbaca9897311\n",
    "layout:nlp:default:38524e2ff135ded55b5286407e7af6b7\n",
    "layout:nlp:default:3a0c5517a87df8d82fd637b83298a3ba\n",
    "layout:nlp:default:6c1101f6231f4d1722c3b9f6d1e25026\n",
    "layout:nlp:default:016ac66a44a906a695afd2228509046a\n",
    "layout:nlp:default:492c7a94d559aa4a88769142d2a68362\n",
    "layout:nlp:default:d15316c12eefdef1ba549eb433797f77\n",
    "layout:nlp:default:7f6284ebe027b1e9a3850fc703858a59\n",
    "layout:nlp:default:32531d07a084b319dce484f53a4cf3fc\n",
    "layout:nlp:default:23559853d9702baaaacbb0c83fd32266\n",
    "layout:nlp:default:71b79ca6db513e7979c3702c595150c2\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:d6f5f54247bd1e58a10b9e7062c636ab\t0;1;2;3;4\n",
    "1\ttile:xla:e3a655daa38e34ec240df959b650ac16\t0;1;2;3;4\n",
    "2\ttile:xla:f8c2c1a1098b2a361c26df668b286c87\t0;1;2;3;4\n",
    "3\ttile:xla:4dd1716853ed46ee4e7d09ede1732de8\t0;1;2;3;4\n",
    "4\ttile:xla:d0a69155b6340748c36724e4bfc34be3\t0;1;2;3;4\n",
    "...\t...\t...\n",
    "889\tlayout:nlp:random:60880ed76de53f4d7a1b960b24f2...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "890\tlayout:nlp:random:23559853d9702baaaacbb0c83fd3...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "891\tlayout:nlp:random:f6c146fc5cf10be4f3accbaca989...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "892\tlayout:nlp:random:32531d07a084b319dce484f53a4c...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "893\tlayout:nlp:random:3a0c5517a87df8d82fd637b83298...\t0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...\n",
    "894 rows Ã— 2 columns\n",
    "\n",
    "43ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã®ã§æ”¹å¤‰ã—ãŸã€‚\n",
    "\"\"\"\n",
    "dataset = TileDataset(layout_nlp_random[\"test\"])\n",
    "tile_xla_predictions = [[] for i in range(len(dataset))]\n",
    "for fold in range(2):\n",
    "    model.load_state_dict(torch.load(f'/kaggle/input/fast-slow-sep/nlp_random/layout_xla_default_best_model_{fold}.pth',map_location=torch.device('cpu') ))\n",
    "    model.eval()\n",
    "    \n",
    "    pbar = tqdm(range(len(dataset)))\n",
    "    for i in pbar:\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = dataset[i]\n",
    "        cfg_ft,nd_ft,nd_op,ind,target = cfg_ft.to(device),nd_ft.to(device),nd_op.to(device),ind.to(device),target.to(device)\n",
    "\n",
    "        out = model(cfg_ft,nd_ft,nd_op,ind) \n",
    "        tile_xla_predictions[i].append(out.cpu().detach().numpy())\n",
    "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:-1] for pred in tile_xla_predictions]\n",
    "tile_xla_predictions[0]\n",
    "\n",
    "#sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
    "for i,filename in enumerate(layout_nlp_random[\"test\"]['file'].values):\n",
    "    id = 'layout:nlp:random:' +filename[:-4]\n",
    "    print(id)\n",
    "    sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub\n",
    "\"\"\"\n",
    "  0%|          | 0/17 [00:00<?, ?it/s]/tmp/ipykernel_23/1750813363.py:16: RuntimeWarning: invalid value encountered in divide\n",
    "  target = (target-min(target))/(max(target) -min(target))\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 38.68it/s]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 39.14it/s]\n",
    "layout:nlp:random:b2fdde3b72980907578648774101543e\n",
    "layout:nlp:random:29886a50d55cfe77a9497bc906c76ce9\n",
    "layout:nlp:random:7105451001e119f65b66570d170b94a8\n",
    "layout:nlp:random:171b0513d8874a427ccfa46d136fbadc\n",
    "layout:nlp:random:60880ed76de53f4d7a1b960b24f20f7d\n",
    "layout:nlp:random:58cc2e418c3a8a19b871e15964b534ad\n",
    "layout:nlp:random:f6c146fc5cf10be4f3accbaca9897311\n",
    "layout:nlp:random:38524e2ff135ded55b5286407e7af6b7\n",
    "layout:nlp:random:3a0c5517a87df8d82fd637b83298a3ba\n",
    "layout:nlp:random:6c1101f6231f4d1722c3b9f6d1e25026\n",
    "layout:nlp:random:016ac66a44a906a695afd2228509046a\n",
    "layout:nlp:random:492c7a94d559aa4a88769142d2a68362\n",
    "layout:nlp:random:d15316c12eefdef1ba549eb433797f77\n",
    "layout:nlp:random:7f6284ebe027b1e9a3850fc703858a59\n",
    "layout:nlp:random:32531d07a084b319dce484f53a4cf3fc\n",
    "layout:nlp:random:23559853d9702baaaacbb0c83fd32266\n",
    "layout:nlp:random:71b79ca6db513e7979c3702c595150c2\n",
    "ID\tTopConfigs\n",
    "0\ttile:xla:d6f5f54247bd1e58a10b9e7062c636ab\t0;1;2;3;4\n",
    "1\ttile:xla:e3a655daa38e34ec240df959b650ac16\t0;1;2;3;4\n",
    "2\ttile:xla:f8c2c1a1098b2a361c26df668b286c87\t0;1;2;3;4\n",
    "3\ttile:xla:4dd1716853ed46ee4e7d09ede1732de8\t0;1;2;3;4\n",
    "4\ttile:xla:d0a69155b6340748c36724e4bfc34be3\t0;1;2;3;4\n",
    "...\t...\t...\n",
    "889\tlayout:nlp:random:60880ed76de53f4d7a1b960b24f2...\t17;604;850;9;150;326;639;288;23;286;627;923;57...\n",
    "890\tlayout:nlp:random:23559853d9702baaaacbb0c83fd3...\t62;976;644;52;218;38;30;275;916;318;618;74;893...\n",
    "891\tlayout:nlp:random:f6c146fc5cf10be4f3accbaca989...\t208;615;715;367;967;594;408;363;649;282;767;55...\n",
    "892\tlayout:nlp:random:32531d07a084b319dce484f53a4c...\t212;76;849;778;847;4;396;482;787;605;934;273;7...\n",
    "893\tlayout:nlp:random:3a0c5517a87df8d82fd637b83298...\t869;518;130;854;967;998;876;240;582;187;573;25...\n",
    "894 rows Ã— 2 columns\n",
    "\n",
    "\"\"\"\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
